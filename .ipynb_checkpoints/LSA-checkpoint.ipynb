{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors,DenseMatrix\n",
    "from pyspark.mllib.common import callMLlibFunc, JavaModelWrapper\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix as sp\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SVD(JavaModelWrapper):\n",
    "    \"\"\"Wrapper around the SVD scala case class\"\"\"\n",
    "    @property\n",
    "    def U(self):\n",
    "        \"\"\" Returns a RowMatrix whose columns are the left singular vectors of the SVD if computeU was set to be True.\"\"\"\n",
    "        u = self.call(\"U\")\n",
    "        if u is not None:\n",
    "        \treturn RowMatrix(u)\n",
    "\n",
    "    @property\n",
    "    def s(self):\n",
    "        \"\"\"Returns a DenseVector with singular values in descending order.\"\"\"\n",
    "        return self.call(\"s\")\n",
    "\n",
    "    @property\n",
    "    def V(self):\n",
    "        \"\"\" Returns a DenseMatrix whose columns are the right singular vectors of the SVD.\"\"\"\n",
    "        return self.call(\"V\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeSVD(row_matrix, k, computeU=False, rCond=1e-9):\n",
    "    \"\"\"\n",
    "    Computes the singular value decomposition of the RowMatrix.\n",
    "    The given row matrix A of dimension (m X n) is decomposed into U * s * V'T where\n",
    "    * s: DenseVector consisting of square root of the eigenvalues (singular values) in descending order.\n",
    "    * U: (m X k) (left singular vectors) is a RowMatrix whose columns are the eigenvectors of (A X A')\n",
    "    * v: (n X k) (right singular vectors) is a Matrix whose columns are the eigenvectors of (A' X A)\n",
    "    :param k: number of singular values to keep. We might return less than k if there are numerically zero singular values.\n",
    "    :param computeU: Whether of not to compute U. If set to be True, then U is computed by A * V * sigma^-1\n",
    "    :param rCond: the reciprocal condition number. All singular values smaller than rCond * sigma(0) are treated as zero, where sigma(0) is the largest singular value.\n",
    "    :returns: SVD object\n",
    "    \"\"\"\n",
    "    java_model = row_matrix._java_matrix_wrapper.call(\"computeSVD\", int(k), computeU, float(rCond))\n",
    "    return SVD(java_model)\n",
    "\n",
    "def pre_process(line):\n",
    "    return [stemmer.stem(word) for word in word_tokenize(line) if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_tf(document):\n",
    "    doc_map = {}\n",
    "    for term in document:\n",
    "        if not term in doc_map:\n",
    "            doc_map[term] = 0\n",
    "        doc_map[term] += 1\n",
    "    return [(x, doc_map[x]) for x in doc_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "stemmer = SnowballStemmer('english')    \n",
    "documents = sc.textFile(\"anarchism_clean.txt\").map(pre_process)\n",
    "docTermFreqs = documents.map(map_tf).cache()\n",
    "\n",
    "\n",
    "docFreqs = docTermFreqs.flatMap(lambda x : x).reduceByKey(add)\n",
    "num_docs = docTermFreqs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idfs = docFreqs.map(lambda x: (x[0], log(num_docs/x[1])))\n",
    "idTerms = idfs.keys().zipWithIndex()\n",
    "term_ids = idTerms.map(lambda x: tuple(reversed(x)))\n",
    "\n",
    "dict_id_terms = dict(idTerms.collect())\n",
    "dict_terms_id = dict(term_ids.collect())\n",
    "dict_term_freqs = dict(docFreqs.collect())\n",
    "dict_idfs = dict(idfs.collect())\n",
    "num_terms = len(dict_id_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapping_function(termFreqs):\n",
    "    docTotalTerms = sum([value[1] for value in termFreqs])\n",
    "    return Vectors.sparse(num_terms, \\\n",
    "                          [(dict_id_terms[term[0]], dict_idfs[term[0]]*dict_term_freqs[term[0]]/docTotalTerms) \\\n",
    "                           for term in termFreqs])\n",
    "    \n",
    "vecs = docTermFreqs.map(mapping_function).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = RowMatrix(vecs)\n",
    "svd = computeSVD(mat,k,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topTerms(svd, numConcepts, numTerms, termsIds):\n",
    "    v = svd.V\n",
    "    topTerms = []\n",
    "    arr = v.toArray().ravel()\n",
    "    for i in range(numConcepts):\n",
    "        offs = i*v.numRows\n",
    "        termWeights = [(termsIds[j], arr[j]) for j in range(0, v.numRows)]\n",
    "        weights_sorted = sorted(termWeights, key=lambda x: x[1].all(), reverse=True)\n",
    "        topTerms += weights_sorted[:numTerms]\n",
    "    return topTerms\n",
    "        \n",
    "def topDocsInTopConcepts(svd, numConcepts, numDocs, docIds):\n",
    "    u = svd.U\n",
    "    topDocs = []\n",
    "    for i in range(numConcepts):\n",
    "        docWeights = u.rows.map(lambda x: x[i]).zipWithUniqueId()\n",
    "        #print(i)\n",
    "        #print (docWeights.top(numDocs))\n",
    "        topDocs += [(x[1],x[0]) for x in docWeights.top(numDocs)]\n",
    "    return topDocs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = topTerms(svd, k, 10, dict_terms_id)\n",
    "td = topDocsInTopConcepts(svd,k,10,dict_terms_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topTermsforTerm(normalizedVS,termId, k=10):\n",
    "    rowVec = normalizedVS[termId,:]\n",
    "    termScores = [(i,t) for i,t in zip(range(len(rowVec)),normalizedVS.dot(rowVec))]\n",
    "    #print(termScores)\n",
    "    return sorted(termScores,key = lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "def multiplyByDiagonalMatrix(A, D):\n",
    "    if isinstance(A,RowMatrix):\n",
    "        n_cols = A.numCols()\n",
    "        n_rows = A.numRows()\n",
    "        A = A.rows.collect()\n",
    "    else:\n",
    "        n_cols = A.numCols\n",
    "        n_rows = A.numRows\n",
    "        \n",
    "    mat = np.empty([n_rows,n_cols])\n",
    "    for i in range(0,n_rows):\n",
    "        for j in range(0,n_cols):\n",
    "            mat[i,j] = A[i][j]*D[j]\n",
    "    return mat\n",
    "\n",
    "def printRelevantTerms(term, svd, k=10):\n",
    "    stemmed_term = stemmer.stem(term)\n",
    "    if stemmed_term not in dict_id_terms:\n",
    "        print (\"Term unknown\")\n",
    "    else:\n",
    "        _id = dict_id_terms[stemmed_term]\n",
    "        vs = multiplyByDiagonalMatrix(svd.V,svd.s)\n",
    "        normalized_vs = normalize(vs, axis=1, norm=\"l2\")\n",
    "        topTerms = topTermsforTerm(normalized_vs,_id, k)\n",
    "\n",
    "        for t in topTerms:\n",
    "            print(dict_terms_id[t[0]],' -> ',t[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topDocsForDoc(normalizedUS, docId, k=10):\n",
    "    docRowArr = normalizedUS[docId,:]\n",
    "    docScores = normalizedUS.dot(docRowArr)\n",
    "    allDocsWeights = [(i,d) for i,d in zip(range(len(docScores)),docScores)]\n",
    "    return sorted(allDocsWeights, key=lambda x: x[1], reverse = True)[:k]\n",
    "\n",
    "def printRelevantDocsforDoc(doc,svd,k=10):\n",
    "    _id = doc\n",
    "    us = multiplyByDiagonalMatrix(svd.U, svd.s)\n",
    "    normalized_us = normalize(us, axis=1, norm=\"l2\")\n",
    "    \n",
    "    topDocs = topDocsForDoc(normalized_us, _id,k)\n",
    "    for d in topDocs:\n",
    "        print('Documento:',d[0],'\\tSimilaridade:\\t',d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topDocsForTerm(svd,termId,k=10):\n",
    "    rowArr = svd.V.toArray()[termId]\n",
    "    us = multiplyByDiagonalMatrix(svd.U,svd.s)\n",
    "    normalized_us = normalize(us, axis=1, norm=\"l2\")\n",
    "    docScores = normalized_us.dot(rowArr)\n",
    "    allDocsWeights = [(i,d) for i,d in zip(range(len(docScores)),docScores)]\n",
    "    return sorted(allDocsWeights, key=lambda x: x[1], reverse = True)[:k]\n",
    "    \n",
    "def printRelevantDocsforTerm(term,svd,k=10):\n",
    "    stemmed_term = stemmer.stem(term)\n",
    "    if stemmed_term not in dict_id_terms:\n",
    "        print (\"Term unknown\")\n",
    "    else:\n",
    "        _id = dict_id_terms[stemmed_term]\n",
    "        topDocs = topDocsForTerm(svd,_id,k)\n",
    "        for d in topDocs:\n",
    "            print('Documento:',d[0],'\\tRelevancia:\\t',d[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def termsToQueryVector(terms):\n",
    "    global dict_id_terms\n",
    "    ids = [dict_id_terms[stemmer.stem(t)] for t in terms if stemmer.stem(t) in dict_id_terms]\n",
    "    values = [dict_idfs[stemmer.stem(t)] for t in terms if stemmer.stem(t) in dict_id_terms] \n",
    "    return Vectors.sparse(len(dict_id_terms),zip(ids,values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def topDocsForTermQuery(svd,query):\n",
    "    termRowVec = svd.V.toArray().T.dot(query.toArray())\n",
    "    US = multiplyByDiagonalMatrix(svd.U,svd.s)\n",
    "    docScores = US.dot(termRowVec)\n",
    "    allDocWeights = sorted([(i,docScores[i]) for i in range(docScores.shape[0])], key=lambda x: x[1], reverse=True)\n",
    "    return allDocWeights[:10]\n",
    "\n",
    "def printRelevantDocs(terms):\n",
    "    global svd\n",
    "    queryVec = termsToQueryVector(terms)\n",
    "    print(\"Para os termos \", terms)\n",
    "    for doc, relev in topDocsForTermQuery(svd, queryVec):\n",
    "        print(\"Documento {},\\tpossui relevancia {}\".format(doc, relev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
