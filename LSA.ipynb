{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors,DenseVector\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.mllib.common import callMLlibFunc, JavaModelWrapper\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"App Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SVD(JavaModelWrapper):\n",
    "    \"\"\"Wrapper around the SVD scala case class\"\"\"\n",
    "    @property\n",
    "    def U(self):\n",
    "        \"\"\" Returns a RowMatrix whose columns are the left singular vectors of the SVD if computeU was set to be True.\"\"\"\n",
    "        u = self.call(\"U\")\n",
    "        if u is not None:\n",
    "        \treturn RowMatrix(u)\n",
    "\n",
    "    @property\n",
    "    def s(self):\n",
    "        \"\"\"Returns a DenseVector with singular values in descending order.\"\"\"\n",
    "        return self.call(\"s\")\n",
    "\n",
    "    @property\n",
    "    def V(self):\n",
    "        \"\"\" Returns a DenseMatrix whose columns are the right singular vectors of the SVD.\"\"\"\n",
    "        return self.call(\"V\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeSVD(row_matrix, k, computeU=False, rCond=1e-9):\n",
    "    \"\"\"\n",
    "    Computes the singular value decomposition of the RowMatrix.\n",
    "    The given row matrix A of dimension (m X n) is decomposed into U * s * V'T where\n",
    "    * s: DenseVector consisting of square root of the eigenvalues (singular values) in descending order.\n",
    "    * U: (m X k) (left singular vectors) is a RowMatrix whose columns are the eigenvectors of (A X A')\n",
    "    * v: (n X k) (right singular vectors) is a Matrix whose columns are the eigenvectors of (A' X A)\n",
    "    :param k: number of singular values to keep. We might return less than k if there are numerically zero singular values.\n",
    "    :param computeU: Whether of not to compute U. If set to be True, then U is computed by A * V * sigma^-1\n",
    "    :param rCond: the reciprocal condition number. All singular values smaller than rCond * sigma(0) are treated as zero, where sigma(0) is the largest singular value.\n",
    "    :returns: SVD object\n",
    "    \"\"\"\n",
    "    java_model = row_matrix._java_matrix_wrapper.call(\"computeSVD\", int(k), computeU, float(rCond))\n",
    "    return SVD(java_model)\n",
    "\n",
    "def pre_process(line):\n",
    "    return [stemmer.stem(word) for word in word_tokenize(line) if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_tf(document):\n",
    "    doc_map = {}\n",
    "    for term in document:\n",
    "        if not term in doc_map:\n",
    "            doc_map[term] = 0\n",
    "        doc_map[term] += 1\n",
    "    return [(x, doc_map[x]) for x in doc_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 200\n",
    "stemmer = SnowballStemmer('english')    \n",
    "documents = sc.textFile(\"anarchism_clean.txt\").map(pre_process)\n",
    "docTermFreqs = documents.map(map_tf).cache()\n",
    "\n",
    "\n",
    "docFreqs = docTermFreqs.flatMap(lambda x : x).reduceByKey(add)\n",
    "num_docs = docTermFreqs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idfs = docFreqs.map(lambda x: (x[0], log(num_docs/x[1])))\n",
    "idTerms = idfs.keys().zipWithIndex()\n",
    "term_ids = idTerms.map(lambda x: tuple(reversed(x)))\n",
    "\n",
    "dict_id_terms = dict(idTerms.collect())\n",
    "dict_terms_id = dict(term_ids.collect())\n",
    "dict_term_freqs = dict(docFreqs.collect())\n",
    "dict_idfs = dict(idfs.collect())\n",
    "num_terms = len(dict_id_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_funcao1(termFreqs):\n",
    "    docTotalTerms = sum([value[1] for value in termFreqs])\n",
    "    return Vectors.sparse(num_terms, \\\n",
    "                          [(dict_id_terms[term[0]], dict_idfs[term[0]]*dict_term_freqs[term[0]]/docTotalTerms) \\\n",
    "                           for term in termFreqs])\n",
    "    \n",
    "vecs = docFreqs.map(map_funcao1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = RowMatrix(vecs)\n",
    "svd = computeSVD(mat,k,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topTerms(svd, numConcepts, numTerms, termsIds):\n",
    "    v = svd.V\n",
    "    topTerms = []\n",
    "    arr = v.toArray().ravel()\n",
    "    for i in range(numConcepts):\n",
    "        offs = i*v.numRows\n",
    "        termWeights = [(termsIds[j], arr[j]) for j in range(0, v.numRows)]\n",
    "#         print (termWeights[0])\n",
    "        weights_sorted = sorted(termWeights, key=lambda x: x[1].all(), reverse=True)\n",
    "        topTerms += weights_sorted\n",
    "    return topTerms[:num_terms]\n",
    "        \n",
    "    \n",
    "\n",
    "def topDocsInTopConcepts(svd, numConcepts, numDocs, docIds):\n",
    "    u = svd.U\n",
    "    for i in range(numConcepts):\n",
    "        docWeights = u.rows.map(lambda x: x.toArray[i])\n",
    "    return docWeights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topTerms(svd, k, 10, dict_terms_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
